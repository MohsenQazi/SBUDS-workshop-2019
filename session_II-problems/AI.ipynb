{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    " \n",
    "num = 2000\n",
    "    \n",
    "img_list = ['zero_'+str(i)+'.png' for i in range(1,num+1)]\n",
    "lbl_list = [0 for i in range(num)]\n",
    "img_list = img_list+['one_'+str(i)+'.png' for i in range(1,num+1)]\n",
    "lbl_list = lbl_list+[1 for i in range(num)]\n",
    "\n",
    "# print img_list,lbl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"AIresearch.settings\")\n",
    "import django\n",
    "django.setup()\n",
    "from basic_model.models import Mnistimage\n",
    "\n",
    "\n",
    "def trainedFiles():\n",
    "    trainedObjects = Mnistimage.objects.exclude(trained_label=3)\n",
    "    images = trainedObjects.values('image')\n",
    "    labels = trainedObjects.values('trained_label')\n",
    "    images = [i['image'] for i in list(images)]\n",
    "    labels = [i['trained_label']-1 for i in list(labels)]\n",
    "\n",
    "    return images,labels\n",
    "img_list,lbl_list = list(trainedFiles())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'MNIST_images/one_6.png', u'MNIST_images/one_17.png', u'MNIST_images/one_28.png', u'MNIST_images/one_23.png', u'MNIST_images/one_10.png', u'MNIST_images/one_18.png', u'MNIST_images/one_30.png', u'MNIST_images/zero_5156.png', u'MNIST_images/one_13.png', u'MNIST_images/zero_3607.png', u'MNIST_images/zero_1.png', u'MNIST_images/zero_13.png']\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print img_list\n",
    "print lbl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_provider(img_list,lbl_list,n):\n",
    "    \n",
    "    images = np.zeros((n,28,28,1))\n",
    "    labels = np.zeros((n,2))\n",
    "    \n",
    "    n_files = len(img_list)\n",
    "    n = min(n,n_files)\n",
    "    \n",
    "    lst = np.arange(n_files)\n",
    "    random.shuffle(lst)\n",
    "    lst = lst[:n]\n",
    "    \n",
    "    for i in range(n):\n",
    "        images[i,:,:,0] = imread('./media/'+img_list[lst[i]])\n",
    "        labels[i,lbl_list[lst[i]]] =1 \n",
    "        \n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_in = tf.placeholder(tf.float32, shape=[None,28,28,1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None,2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "x = tf.layers.conv2d(x_in,filters=5,kernel_size=3,strides=(1, 1),padding='same',\n",
    "            activation=tf.nn.relu)\n",
    "x = tf.layers.max_pooling2d(x,pool_size=2,strides=2)\n",
    "\n",
    "x = tf.layers.conv2d(x,filters=5,kernel_size=3,strides=(1, 1),padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "x = tf.layers.max_pooling2d(x,pool_size=2,strides=2)\n",
    "\n",
    "x = tf.contrib.layers.flatten(x)\n",
    "x = tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "y_conv = tf.layers.dense(x,2,activation=tf.nn.softmax)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model\n",
      "0, 0.05\n",
      "10, 0.06\n",
      "20, 0.06\n",
      "30, 0.07\n",
      "40, 0.07\n",
      "50, 0.07\n",
      "60, 0.07\n",
      "70, 0.07\n",
      "80, 0.07\n",
      "90, 0.07\n"
     ]
    }
   ],
   "source": [
    "def train(img_list,lbl_list,restore=1,model_add='model'):\n",
    "    sess = tf.InteractiveSession()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    if restore:\n",
    "#         tf.reset_default_graph()\n",
    "        saver.restore(sess, model_add+'/model')\n",
    "    else:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "    for i in range(100):\n",
    "        xp,yp = data_provider(img_list,lbl_list,100)\n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x_in: xp, y_: yp, keep_prob: 1.0})\n",
    "            print('{:d}, {:2.2f}'.format(i, train_accuracy))\n",
    "        train_step.run(feed_dict={x_in: xp, y_: yp, keep_prob: 0.8})\n",
    "\n",
    "    saver.save(sess, model_add+'/model')\n",
    "    \n",
    "train(img_list,lbl_list,restore=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(img_path,model_add='model'):\n",
    "    images = np.zeros((1,28,28,1))\n",
    "    images[0,:,:,0] = imread(img_path)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model_add+'/model')\n",
    "\n",
    "    y_out = sess.run(y_conv,feed_dict={x_in: images, keep_prob: 1.0})\n",
    "    return np.argmax(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = './media/MNIST_images/zero_15.png'\n",
    "predict(img_path,model_add='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58333333333333337"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_all(model_add='model'):\n",
    "\n",
    "    all_objects = Mnistimage.objects.all()\n",
    "    images_lst = all_objects.values('image')\n",
    "    images_id = all_objects.values('imageid')\n",
    "    labels = all_objects.values('trained_label')\n",
    "    images_lst = [i['image'] for i in list(images_lst)]\n",
    "    images_id = [i['imageid'] for i in list(images_id)]\n",
    "    labels = [i['trained_label']-1 for i in list(labels)]\n",
    "    \n",
    "    n_img = len(labels)\n",
    "    \n",
    "    images = np.zeros((n_img,28,28,1))\n",
    "    \n",
    "    \n",
    "    for i in range(n_img):\n",
    "        images[i,:,:,0] = imread('./media/'+images_lst[i]) \n",
    "    \n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model_add+'/model')\n",
    "\n",
    "    y_out = sess.run(y_conv,feed_dict={x_in: images, keep_prob: 1.0})\n",
    "    y_pred = np.argmax(y_out,axis=1)\n",
    "    for i in images_id:\n",
    "        mnistimage=Mnistimage.objects.get(imageid=i)\n",
    "        mnistimage.predicted_label=1\n",
    "        mnistimage.save()\n",
    "    \n",
    "    \n",
    "    return np.sum(1.*(y_pred==labels))/n_img\n",
    "\n",
    "predict_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def trainedFiles(n):\n",
    "    trainedObjects = Mnistimage.objects.filter(trained_label=3)\n",
    "    images = trainedObjects.values('image')\n",
    "    images_id = trainedObjects.values('imageid')\n",
    "    labels = trainedObjects.values('trained_label')\n",
    "    \n",
    "    images = [i['image'] for i in list(images)]\n",
    "    images_id = [i['imageid'] for i in list(images_id)]\n",
    "    \n",
    "    n_img = len(labels)\n",
    "    r_lst = np.arange(n_img)\n",
    "    random.shuffle(r_lst)\n",
    "    r_inds = r_lst[:n]\n",
    "    \n",
    "    for i in r_inds:\n",
    "    \n",
    "    \n",
    "        print images[i]\n",
    "    \n",
    "        if 'one' in images[i]:\n",
    "            true_lbl = 1\n",
    "        else:\n",
    "            true_lbl = 0\n",
    "    \n",
    "        mnistimage=Mnistimage.objects.get(imageid=images_id[i]) \n",
    "        mnistimage.predicted_label=true_lbl\n",
    "        mnistimage.save()\n",
    "    \n",
    "\n",
    "trainedFiles(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
